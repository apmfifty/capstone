{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文主要侧重embedding模型\n",
    "\n",
    "- Reference 1: Kaggle Kernel [Code sharing, 13th place, no external data](https://www.kaggle.com/c/rossmann-store-sales/discussion/17979)\n",
    "- Reference 2: Kaggle Kernel-[A Journey through Rossmann Stores](https://www.kaggle.com/omarelgabry/rossmann-store-sales/a-journey-through-rossmann-stores)\n",
    "- Reference 3: Kaggle Kernel-[Predict_sales_with_pandas](https://www.kaggle.com/zygmunt/rossmann-store-sales/predict-sales-with-pandas-py)\n",
    "- [XGBoost:Notes on Parameter Tuning](http://xgboost.readthedocs.io/en/latest/how_to/param_tuning.html)\n",
    "- [XGBoost Parameters](http://xgboost.readthedocs.io/en/latest/parameter.html)\n",
    "- [Complete Guide to Parameter Tuning in XGBoost (with codes in Python)](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/)\n",
    "\n",
    "\n",
    "\n",
    "# 训练XGBoost模型\n",
    "Refers to [XGBoost Feature Importance](https://www.kaggle.com/cast42/rossmann-store-sales/xgboost-in-python-with-rmspe-v2)\n",
    "\n",
    "Based on https://www.kaggle.com/justdoit/rossmann-store-sales/xgboost-in-python-with-rmspe/code\n",
    "\n",
    "Public Score :  0.11389\n",
    "\n",
    "Private Validation Score :  0.096959\n",
    "\n",
    "#### 在运行时，每个部分可以单独运行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习纳米学位\n",
    "## 毕业项目开题报告\n",
    "赵鹏举  \n",
    "2017-03-16\n",
    "\n",
    "## Rossmann药店销售额预测\n",
    "### 项目背景\n",
    "销售预测对于每一个企业都非常重要，机器学习的方法在其中得到了非常广泛的应用，掌握进行预测的常用方法和工作流程对于以后从事数据分析工作有着巨大的现实意义。\n",
    "\n",
    "本项目来自Kaggle比赛[Rossman Store Sales](https://www.kaggle.com/c/rossmann-store-sales#description).  截至2015年，Rossmann在欧洲7个国家运行着超过3000家连锁药店，这些药店的营收会受到促销、竞争者、国家和学校假期、季节、地域等因素的影响。Rossmann希望参加比赛项目的选手，可以准确地地预测出位于德国1115家药店在六周内每天的销售情况；进而利用可靠的销售预测情况帮助药店经理制定更加高效的工作安排。\n",
    "\n",
    "比赛过程中，第一名[Gert](https://kaggle2.blob.core.windows.net/forum-message-attachments/102102/3454/Rossmann_nr1_doc.pdf)在原有数据集基础上，构造出临近信息、时间信息、趋势信息等特征，并采用XGBoost方法训练模型；第三名[Cheng Guo](https://arxiv.org/pdf/1604.06737.pdf) 将原本主要用于自然语言处理的深度学习entity embedding模型应用到类别特征中，取得第三名。\n",
    "\n",
    "### 问题描述\n",
    "本问题为监督学习中的回归问题：已知1115家药店的信息以及每家药店在2年多时间内每天的销售情况，需要对接下来6周内每家药店的销售状况进行预测。回归问题的常见机器学习方法有K近邻学习、线性回归、决策树、随机森林、XGBoost、神经网络等；而实际中，为了训练出效果较好的模型，一般需要根据数据集的特点，进行特征工程，构造出有用的新特征，并对特征进行选择，同时注意防止过拟合。\n",
    "\n",
    "在本问题提供的数据集中，销售数据作为标记值，其他属性作为特征，对选择的模型进行训练；模型的预测销售数据与标记销售数据之间的差异可以用来对模型进行评估；训练好的模型，对测试数据的预测是可以再现的。\n",
    "\n",
    "### 输入数据\n",
    "输入数据包含 train.csv和store.csv：\n",
    "\n",
    "- train.csv是历史销售数据，每条信息包含了药店编号、日期、星期几、是否营业、是否节假日、是否促销、当日销售额以及客户数量；\n",
    "- store.csv是药店补充数据，每条信息包含了点药店编号、药店类型、商品组合、最近竞争者距离及开店时间、促销有无、促销间隔和开始时间。\n",
    "\n",
    "输入的数据对于药店销售预测是非常有用的：日期和星期几等可以提供销售额周期性的时间标定；是否节假日和促销，以及每家药店的信息和竞争者的信息，对于销售额也会有一定影响。\n",
    "\n",
    "### 解决办法\n",
    "本项目将尝试三种方法进行最终预测：\n",
    "\n",
    "- 方法1：采用XGBoost方法；XGBoost模型是一种有监督的集成学习方法，可以直观理解为对决策树的集成，是非常有效的解决非结构化数据的方法，在Kaggle比赛中得到广泛的应用；\n",
    "- 方法2：采用Entity Embedding方法；Entity Embedding属于深度学习中处理自然语言的重要方法，用来表示不同单词之间的关系，本文将用来研究不同特征之间的关系。\n",
    "- 方法3：前两种方法的集成；\n",
    "\n",
    "本项目将基于python进行实现，将会主要用到numpy、pandas、matplotlib、seaborn、sklearn、XGBoost、TensorFlow、Keras等函数库。\n",
    "\n",
    "### 基准模型\n",
    "本项目将采用两个基准模型：\n",
    "\n",
    "- 基准一：具有相同特征参数数据子集的中位数；采用的特征包含药店编号、星期几、是否促销、药店类型、商品组合、是否节假日等；\n",
    "- 基准二：Kaggle Private/Public Leader Board；Kaggle Leader Borad记录了参赛者的预测结果和最终名次，所以可用来衡量本项目能够达到怎样的最终预测结果；Public Leader Board使用了33%测试数据的预测结果，而Private Leader Board使用了67%测试数据的预测结果。\n",
    "\n",
    "为了避免对测试数据的过拟合而导致的效果提升，本项目在完成过程中，将主要根据输入数据中划分出来的验证集对模型进行评估和优化，用Public Leader Board作为训练过程中过拟合的验证手段，仅在最终用Private Leader Board对结果进行评估。\n",
    "\n",
    "### 评估指标\n",
    "本项目采用Kaggle比赛的评估指标：RMSPE（误差百分比的均方差），可表示为\n",
    "$$\n",
    "RMSPE= \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(\\frac{y_i-\\hat{y_i}}{y_i})^2}\n",
    "$$\n",
    "其中，任何当天销售额为0的数据在评估时将被忽略； $y_i$ 表示某药店在某天的实际销售额，而$\\hat{y_i}$ 表示该药店在对应这一天的预测销售额。\n",
    "\n",
    "### 设计大纲\n",
    "工作流程：\n",
    "\n",
    "1. 数据读入：将train.csv、store.csv、test.csv读入\n",
    "2. 数据可视化：针对不同的特征，对数据进行可视化；\n",
    "   1. 展示不同分类特征（如星期几、节假日、促销、药店类型、商品组合等）对于销售额的影响\n",
    "   2. 展示时间序列对于对于销售额的影响，比如指定店铺随着时间的销售额变化、不同因素（促销、装修、竞争等）产生的销售额变化；\n",
    "   3. 观察是否有异常数据\n",
    "   4. 展示不同特征之间的相关性\n",
    "3. 数据整理和特征工程\n",
    "   1. 对数据中缺失值、异常值进行处理\n",
    "   2. 分析数据的相关性，并进行数据降维处理\n",
    "   3. 进行数据聚类分析\n",
    "   4. 根据需要，对数据进行清理（如归一化、采用对数处理改善分布状况）、聚合\n",
    "   5. 构造更多的特征（如更详细时间信息、趋势信息等）\n",
    "4. 训练基准模型\n",
    "   1. 划分训练集、验证集、测试集\n",
    "   2. 训练并评估基准模型\n",
    "5. 训练XGBoost模型\n",
    "   1. 进行特征选择，找出效果较好的特征组合；\n",
    "   2. 训练不同的模型\n",
    "   3. 对较好的模型进行集成\n",
    "   4. 评估模型\n",
    "6. 训练、评估、优化entity embedding模型\n",
    "   1. 选择合适的特征，搭建entity embedding模型\n",
    "   2. 搭建神经网络模型\n",
    "   3. 训练、评估、优化模型及特征选择\n",
    "7. 对XGBoost模型和entity embedding模型进行集成，并评估\n",
    "8. 结果分析并完成报告\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备工作\n",
    "### 0.1 调入库函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#基本计算类\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "#可视化\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display \n",
    "\n",
    "#机器学习库函数\n",
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Dropout,Activation,Reshape\n",
    "from keras.layers import Merge\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#时间类\n",
    "import time\n",
    "import datetime\n",
    "from isoweek import Week\n",
    "\n",
    "#文件类\n",
    "import os\n",
    "\n",
    "#其他\n",
    "import itertools\n",
    "import operator\n",
    "\n",
    "#基本设定\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 定义评估指标\n",
    "本项目采用Kaggle比赛的评估指标：RMSPE（误差百分比的均方差），可表示为\n",
    "$$\n",
    "RMSPE= \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(\\frac{y_i-\\hat{y_i}}{y_i})^2}\n",
    "$$\n",
    "其中，任何当天销售额为0的数据在评估时将被忽略； $y_i$ 表示某药店在某天的实际销售额，而$\\hat{y_i}$ 表示该药店在对应这一天的预测销售额。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 Setting seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed_1=42\n",
    "seed_2=43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 训练基准模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.0 将处理好的数据从本地硬盘读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_train_store_raw_df='train_store_raw_df.pickle'\n",
    "# file_test_store_raw_df='test_store_raw_df.pickle'\n",
    "file_feature='feature_x_list.pickle'\n",
    "path='Capstone_Project_Rossman_Sales_Prediction_1'\n",
    "\n",
    "train_store_raw_df=pd.read_pickle(os.path.join(path, file_train_store_raw_df))\n",
    "# test_store_raw_df=pd.read_pickle(os.path.join(path, file_test_store_raw_df))\n",
    "feature_x_list=pd.read_pickle(os.path.join(path, file_feature)).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 从训练集中划分出验证集，基准模型将基于验证集进行度量\n",
    "- Kaggle没有提供测试集数据的真实标记值, Kaggle Public/Private Leader Board适合作为衡量模型泛化能力的最终验证；当模型训练结束后，可以作为验证模型是否过拟合的工具，同时也可以参考Leader Board的结果和排名来估计模型优化的潜力；\n",
    "- 本项目在完成过程中，将最后六周的数据作为验证集，用余下的训练集训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_train=train_store_raw_df['Date']<'2015-06-15'\n",
    "mask_valid=train_store_raw_df['Date']>='2015-06-15'\n",
    "train_store_df=train_store_raw_df[mask_train]\n",
    "valid_store_df=train_store_raw_df[mask_valid]\n",
    "benchmark_valid_store_df=valid_store_df.copy()\n",
    "# benchmark_test_store_df=test_store_raw_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 挑选出最优的特征组合训练基准模型\n",
    "\n",
    "#### 3.2.1  训练基准模型\n",
    "- 基准模型采用具有相同特征参数数据子集的中位数；\n",
    "- 采用的特征包含药店编号、星期几，月份、是否促销、当天是否促销2等；\n",
    "- 将特征组合与对应RMSPE存到dict features_RMSPE\n",
    "\n",
    "#### 3.2.2 对验证集进行测试\n",
    "- 利用选好的特征，训练出基准模型\n",
    "- 将model结果以dict形式进行保存，以便于高效计算\n",
    "- 使用训练好的基准模型对验证集进行测试：applymap方法可以非常高效地求出映射结果\n",
    "\n",
    "#### 3.2.3 定义评估函数\n",
    "本项目采用Kaggle比赛的评估指标：RMSPE（误差百分比的均方差），可表示为\n",
    "$$\n",
    "RMSPE= \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(\\frac{y_i-\\hat{y_i}}{y_i})^2}\n",
    "$$\n",
    "其中，任何当天销售额为0的数据在评估时将被忽略； $y_i$ 表示某药店在某天的实际销售额，而$\\hat{y_i}$ 表示该药店在对应这一天的预测销售额。\n",
    "\n",
    "#### 3.2.4 求出基准模型在验证集上的RMSPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#使用训练好的基准模型对验证集进行测试：applymap方法可以非常高效地求出映射结果\n",
    "def predict_benchmark_model(df,features,map_dict):\n",
    "    mask_0=df['Open']==0\n",
    "    mask_1=df['Open']!=0\n",
    "    df.loc[mask_0,'Sales_Predicted']=0\n",
    "    df['tuple_map']=df[features].apply(tuple,axis=1)\n",
    "    df.loc[mask_1,'Sales_Predicted']=df.loc[mask_1,'tuple_map'].map(map_dict)\n",
    "    return df\n",
    "\n",
    "#定义评估函数\n",
    "def calc_RMSPE(input_df,true_label='Sales',predicted_label='Sales_Predicted'):\n",
    "    mask=input_df[true_label]>0\n",
    "    sale=input_df.loc[mask,[true_label,predicted_label]]\n",
    "    sale['errror']=np.power((sale[true_label]-sale[predicted_label])/sale[true_label],2.0)\n",
    "    return np.sqrt(np.sum(sale['errror'])/(len(sale)))\n",
    "\n",
    "#采用的特征包含药店编号、星期几，月份、是否促销、当天是否促销2等；\n",
    "features_benchmark=(['Store','DayOfWeek','Promo','Month','InPromo2Today'])\n",
    "#将特征组合与对应RMSPE存到dict features_RMSPE\n",
    "features_RMSPE={}\n",
    "\n",
    "#提取出所有可能的特征组合放入subset\n",
    "for L in range(2, len(features_benchmark)+1):\n",
    "    for subset in itertools.combinations(features_benchmark, L):\n",
    "        valid_df=benchmark_valid_store_df.copy()\n",
    "        \n",
    "        features=list(subset)\n",
    "        features_sales=features+['Sales']\n",
    "        \n",
    "        #利用选好的特征，训练出基准模型\n",
    "        benchmark_model=train_store_df[train_store_df['Open']==1][features_sales].groupby(features).median()\n",
    "        #将model结果以dict形式进行保存，以便于高效计算\n",
    "        benchmark_model_dict=benchmark_model['Sales'].to_dict()\n",
    "        \n",
    "        valid_df= predict_benchmark_model(valid_df,features,benchmark_model_dict)   \n",
    "        RMSPE_valid_benchmark=calc_RMSPE(valid_df)\n",
    "        features_RMSPE[subset]=RMSPE_valid_benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.5 打印features_RMSPE中数值较小的三个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------RMSPE较小的三个特征组合与在对应验证集的RMSPE-------------\n",
      "('Store', 'DayOfWeek', 'Promo', 'InPromo2Today') : 0.140907493872\n",
      "('Store', 'DayOfWeek', 'Promo') : 0.141226490165\n",
      "('Store', 'DayOfWeek', 'Promo', 'Month', 'InPromo2Today') : 0.14656682642\n"
     ]
    }
   ],
   "source": [
    "#打印features_RMSPE中数值较小的三个\n",
    "sorted_RMSPE = sorted(features_RMSPE.items(), key=operator.itemgetter(1))\n",
    "print(\"-----------RMSPE较小的三个特征组合与在对应验证集的RMSPE-------------\")\n",
    "for ii in range(3):\n",
    "    print sorted_RMSPE[ii][0],':',sorted_RMSPE[ii][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####3.3 训练基准模型，并在测试集上进行预测，并提交到Kaggle查看结果\n",
    "#- 把RMSPE最小的特征赋给features_benchmark，并使用所有的train_store_raw_df数据训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 利用挑选的特征训练基准模型，并在验证集上预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基准模型在验证集上的RMSPE:0.140907\n"
     ]
    }
   ],
   "source": [
    "features_benchmark=list(min(features_RMSPE, key=features_RMSPE.get))\n",
    "features_benchmark_sales=features_benchmark+['Sales']\n",
    "\n",
    "#利用选好的特征，训练出基准模型\n",
    "benchmark_model=train_store_df[train_store_df['Open']==1][features_benchmark_sales].groupby(features_benchmark).median()\n",
    "#将model结果以dict形式进行保存，以便于高效计算\n",
    "benchmark_model_dict=benchmark_model['Sales'].to_dict()\n",
    "        \n",
    "valid_df= predict_benchmark_model(valid_df,features_benchmark,benchmark_model_dict)   \n",
    "RMSPE_valid_benchmark=calc_RMSPE(valid_df)\n",
    "print('基准模型在验证集上的RMSPE:{:.6f}'.format(RMSPE_valid_benchmark))\n",
    "\n",
    "# benchmark_model=train_store_raw_df[train_store_raw_df['Open']==1][features_benchmark_sales].groupby(features_benchmark).median()\n",
    "# benchmark_model_dict=benchmark_model['Sales'].to_dict()\n",
    "\n",
    "# benchmark_test_store_df= predict_benchmark_model(benchmark_test_store_df,features_benchmark,benchmark_model_dict)   \n",
    "\n",
    "# benchmark_test_output=benchmark_test_store_df.ix[:,['Id','Sales_Predicted']].rename(columns={'Sales_Predicted': 'Sales'})\n",
    "# benchmark_test_output.sort_values(by='Id',inplace=True)\n",
    "# path='Capstone_Project_Rossman_Sales_Prediction_1'\n",
    "# filename='benchmark_model_test_'+'features_'+'_'.join(features_benchmark)+'.csv'\n",
    "# benchmark_test_output.to_csv(os.path.join(path, filename),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #### [Kaggle Leader Board Result](https://www.kaggle.com/c/rossmann-store-sales/submissions):\n",
    "\n",
    "# |    Kaggle Leader Board   | Result |\n",
    "# | ---------- | --- |\n",
    "# | Private |  0.14807 |\n",
    "# | Public       |  0.14044 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 搭建Embedding模型，并预测结果\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5.0数据读入及预处理\n",
    "#### 5.0.1 将处理好的数据从本地硬盘读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_train_store_raw_df='train_store_raw_df.pickle'\n",
    "# file_test_store_raw_df='test_store_raw_df.pickle'\n",
    "file_feature='feature_x_list.pickle'\n",
    "path='Capstone_Project_Rossman_Sales_Prediction_1'\n",
    "\n",
    "train_store_raw_df=pd.read_pickle(os.path.join(path, file_train_store_raw_df))\n",
    "# test_store_raw_df=pd.read_pickle(os.path.join(path, file_test_store_raw_df))\n",
    "feature_x_list=pd.read_pickle(os.path.join(path, file_feature)).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.0.2 每个特征所对应的unique数值\n",
    "- dict_feature_range：每个feature所对应的范围\n",
    "- dict_feature_offset：每个feature最小值移到0所对应的offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store                          : unique= 1115  ,max= 1115  ,min= 1     ,range= 1115  ,offset= 1    \n",
      "DayOfWeek                      : unique= 7     ,max= 7     ,min= 1     ,range= 7     ,offset= 1    \n",
      "Year                           : unique= 3     ,max= 2015  ,min= 2013  ,range= 3     ,offset= 2013 \n",
      "Month                          : unique= 12    ,max= 12    ,min= 1     ,range= 12    ,offset= 1    \n",
      "Day                            : unique= 31    ,max= 31    ,min= 1     ,range= 31    ,offset= 1    \n",
      "DayOfYear                      : unique= 365   ,max= 365   ,min= 1     ,range= 365   ,offset= 1    \n",
      "StoreType_cat                  : unique= 4     ,max= 3     ,min= 0     ,range= 4     ,offset= 0    \n",
      "Assortment_cat                 : unique= 3     ,max= 2     ,min= 0     ,range= 3     ,offset= 0    \n",
      "StateHoliday_cat               : unique= 4     ,max= 3     ,min= 0     ,range= 4     ,offset= 0    \n",
      "SchoolHoliday                  : unique= 2     ,max= 1     ,min= 0     ,range= 2     ,offset= 0    \n",
      "Promo                          : unique= 2     ,max= 1     ,min= 0     ,range= 2     ,offset= 0    \n",
      "Promo2                         : unique= 2     ,max= 1     ,min= 0     ,range= 2     ,offset= 0    \n",
      "InPromo2Today                  : unique= 2     ,max= 1     ,min= 0     ,range= 2     ,offset= 0    \n",
      "DaysCountSinceCompetition_log  : unique= 15    ,max= 15.0  ,min= 0.0   ,range= 16    ,offset= 0    \n",
      "InCompetition                  : unique= 1     ,max= 1     ,min= 1     ,range= 1     ,offset= 1    \n",
      "InCompetitionToday             : unique= 2     ,max= 1     ,min= 0     ,range= 2     ,offset= 0    \n",
      "CompetitionDistance_log        : unique= 14    ,max= 18.0  ,min= 4.0   ,range= 15    ,offset= 4    \n",
      "DaysCountSincePromo2_log       : unique= 11    ,max= 11.0  ,min= 0.0   ,range= 12    ,offset= 0    \n"
     ]
    }
   ],
   "source": [
    "dict_feature_range={}\n",
    "dict_feature_offset={}\n",
    "\n",
    "for ii in feature_x_list:\n",
    "    unique_list=train_store_raw_df[ii].unique()\n",
    "    max_v=max(unique_list)\n",
    "    min_v=min(unique_list)\n",
    "    dict_feature_range[ii]=(int)(max_v-min_v+1)\n",
    "    dict_feature_offset[ii]=(int)(min_v)\n",
    "    print '{0: <30}'.format(ii),':','unique=','{0: <5}'.format(len(unique_list)),\\\n",
    "    ',max=','{0: <5}'.format((max_v)),',min=','{0: <5}'.format((min_v)), \\\n",
    "    ',range=','{0: <5}'.format((dict_feature_range[ii])),',offset=','{0: <5}'.format((dict_feature_offset[ii]))\n",
    "    \n",
    "\n",
    "\n",
    "#     print ii,':','unique=',len(unique_list),',max=',max_v,',min=',min_v, \\\n",
    "#     ',range=',dict_feature_range[ii],',offset=',dict_feature_offset[ii]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.0.3 将数据对应feature_x_list每列添加offset，将数据的最小值设为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store                          : unique= 1115  ,max= 1114  ,min= 0     ,range= 1115  ,offset= 0    \n",
      "DayOfWeek                      : unique= 7     ,max= 6     ,min= 0     ,range= 7     ,offset= 0    \n",
      "Year                           : unique= 3     ,max= 2     ,min= 0     ,range= 3     ,offset= 0    \n",
      "Month                          : unique= 12    ,max= 11    ,min= 0     ,range= 12    ,offset= 0    \n",
      "Day                            : unique= 31    ,max= 30    ,min= 0     ,range= 31    ,offset= 0    \n",
      "DayOfYear                      : unique= 365   ,max= 364   ,min= 0     ,range= 365   ,offset= 0    \n",
      "StoreType_cat                  : unique= 4     ,max= 3     ,min= 0     ,range= 4     ,offset= 0    \n",
      "Assortment_cat                 : unique= 3     ,max= 2     ,min= 0     ,range= 3     ,offset= 0    \n",
      "StateHoliday_cat               : unique= 4     ,max= 3     ,min= 0     ,range= 4     ,offset= 0    \n",
      "SchoolHoliday                  : unique= 2     ,max= 1     ,min= 0     ,range= 2     ,offset= 0    \n",
      "Promo                          : unique= 2     ,max= 1     ,min= 0     ,range= 2     ,offset= 0    \n",
      "Promo2                         : unique= 2     ,max= 1     ,min= 0     ,range= 2     ,offset= 0    \n",
      "InPromo2Today                  : unique= 2     ,max= 1     ,min= 0     ,range= 2     ,offset= 0    \n",
      "DaysCountSinceCompetition_log  : unique= 15    ,max= 15.0  ,min= 0.0   ,range= 16    ,offset= 0    \n",
      "InCompetition                  : unique= 1     ,max= 0     ,min= 0     ,range= 1     ,offset= 0    \n",
      "InCompetitionToday             : unique= 2     ,max= 1     ,min= 0     ,range= 2     ,offset= 0    \n",
      "CompetitionDistance_log        : unique= 14    ,max= 14.0  ,min= 0.0   ,range= 15    ,offset= 0    \n",
      "DaysCountSincePromo2_log       : unique= 11    ,max= 11.0  ,min= 0.0   ,range= 12    ,offset= 0    \n"
     ]
    }
   ],
   "source": [
    "modified_train_store_raw_df=train_store_raw_df.copy()\n",
    "# modified_test_store_raw_df=test_store_raw_df.copy()\n",
    "for col in feature_x_list:\n",
    "    modified_train_store_raw_df[col]=modified_train_store_raw_df[col]-dict_feature_offset[col]\n",
    "#     modified_test_store_raw_df[col]=modified_test_store_raw_df[col]-dict_feature_offset[col]\n",
    "    \n",
    "for ii in feature_x_list:\n",
    "    unique_list=modified_train_store_raw_df[ii].unique()\n",
    "    max_v=max(unique_list)\n",
    "    min_v=min(unique_list)\n",
    "    print '{0: <30}'.format(ii),':','unique=','{0: <5}'.format(len(unique_list)),\\\n",
    "    ',max=','{0: <5}'.format((max_v)),',min=','{0: <5}'.format((min_v)), \\\n",
    "    ',range=','{0: <5}'.format((int)(max_v-min_v+1)),',offset=','{0: <5}'.format((int)(min_v))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.0.4 构造train_df数据，valid_df数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask_train=(modified_train_store_raw_df['Date']<'2015-06-15') &(modified_train_store_raw_df['Outlier_3']==False) \\\n",
    "            & (modified_train_store_raw_df['Open']==1) & (modified_train_store_raw_df['Sales']>0)\n",
    "mask_valid=(modified_train_store_raw_df['Date']>='2015-06-15') & (modified_train_store_raw_df['Open']==1)\\\n",
    "            & (modified_train_store_raw_df['Sales']>0)#&(modified_train_store_raw_df['Outlier_3']==False)\n",
    "\n",
    "df_train=modified_train_store_raw_df.loc[mask_train,feature_x_list]\n",
    "df_valid=modified_train_store_raw_df.loc[mask_valid,feature_x_list]\n",
    "y_train_data=np.array(modified_train_store_raw_df.loc[mask_train,'Sales'])\n",
    "y_valid_data=np.array(modified_train_store_raw_df.loc[mask_valid,'Sales'])\n",
    "\n",
    "# df_test=modified_test_store_raw_df.loc[modified_test_store_raw_df['Open']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.0.5 构造embedding模型所需要的train, valid数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_data=[]\n",
    "x_valid_data=[]\n",
    "for ii in feature_x_list:\n",
    "    x_train_data.append(np.array(df_train[ii]))\n",
    "    x_valid_data.append(np.array(df_valid[ii]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 搭建embedding模型\n",
    "- 构造list models，将每个feature对应的embedding装进去\n",
    "    - 输入range: dict_feature_range\n",
    "    - 对应的embedding数目:calc_embedding_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_embedding_space(x):\n",
    "    dict_map={\n",
    "        1115:50,\n",
    "        365:30,\n",
    "        31:10,\n",
    "        16:10,\n",
    "        15:10,\n",
    "        12:8,\n",
    "        7:6,\n",
    "        4:3,        \n",
    "        3:2,\n",
    "        2:1,\n",
    "        1:1\n",
    "    }\n",
    "    return dict_map[x]\n",
    "\n",
    "\n",
    "models=[]\n",
    "for ii in feature_x_list:\n",
    "    input_range=dict_feature_range[ii]\n",
    "    \n",
    "#     if input_range ==2 :\n",
    "#         temp_name='Dense_'+ii\n",
    "#         model= Sequential(name=temp_name)\n",
    "#         model.add(Dense(1, input_dim=1))\n",
    "#         models.append(model)\n",
    "#     else:    \n",
    "    embedding_space=calc_embedding_space(input_range)        \n",
    "    temp_name='Embedding_'+ii\n",
    "    model=Sequential(name=temp_name)\n",
    "    model.add(Embedding(input_range,embedding_space,input_length=1))\n",
    "    model.add(Reshape((embedding_space, ), input_shape=(1,embedding_space)))\n",
    "    models.append(model)\n",
    "\n",
    "\n",
    "    \n",
    "def create_embedding_model():\n",
    "    dropout_rate=0.1\n",
    "\n",
    "    embedding_model=Sequential()\n",
    "    embedding_model.add(Merge(models,mode='concat',concat_axis=-1))\n",
    "\n",
    "    embedding_model.add(Dense(512,kernel_initializer='uniform'))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dense(128,kernel_initializer='uniform'))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dense(32,kernel_initializer='uniform'))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dropout(dropout_rate))\n",
    "    embedding_model.add(Dense(1))\n",
    "    embedding_model.add(Activation('sigmoid'))\n",
    "\n",
    "    embedding_model.compile(loss='mean_absolute_error',optimizer='adam')\n",
    "    return embedding_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5.2 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/10\n",
      "786180/786180 [==============================] - 36s - loss: 0.0173 - val_loss: 0.0114\n",
      "Epoch 2/10\n",
      "786180/786180 [==============================] - 36s - loss: 0.0092 - val_loss: 0.0100\n",
      "Epoch 3/10\n",
      "786180/786180 [==============================] - 37s - loss: 0.0076 - val_loss: 0.0097\n",
      "Epoch 4/10\n",
      "786180/786180 [==============================] - 37s - loss: 0.0072 - val_loss: 0.0097\n",
      "Epoch 5/10\n",
      "786180/786180 [==============================] - 36s - loss: 0.0070 - val_loss: 0.0093\n",
      "Epoch 6/10\n",
      "786180/786180 [==============================] - 36s - loss: 0.0068 - val_loss: 0.0091\n",
      "Epoch 7/10\n",
      "786180/786180 [==============================] - 36s - loss: 0.0066 - val_loss: 0.0091\n",
      "Epoch 8/10\n",
      "786180/786180 [==============================] - 37s - loss: 0.0065 - val_loss: 0.0092\n",
      "Epoch 9/10\n",
      "786180/786180 [==============================] - 36s - loss: 0.0064 - val_loss: 0.0092\n",
      "Epoch 10/10\n",
      "786180/786180 [==============================] - 37s - loss: 0.0063 - val_loss: 0.0090\n",
      "train_rmspe :0.152633,\tvalid_rmspe:0.128793\n"
     ]
    }
   ],
   "source": [
    "max_log_y=np.max(np.log(y_train_data))\n",
    "\n",
    "def _val_for_fit(val):\n",
    "    val=np.log(val)\n",
    "    return val/max_log_y\n",
    "def _val_for_pred(val):\n",
    "    return np.exp(val*max_log_y)\n",
    "\n",
    "def calc_predict_rmspe(trained_model,x_data,y_data):\n",
    "    flag=y_data>0\n",
    "    predicted_value=trained_model.predict( x_data).flatten()\n",
    "    return np.sqrt(np.mean(np.power((_val_for_pred(predicted_value[flag])-y_data[flag])/y_data[flag],2.0)))\n",
    "    \n",
    "    \n",
    "\n",
    "nb_epoch=10\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=256\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/15\n",
      "786180/786180 [==============================] - 31s - loss: 0.0147 - val_loss: 0.0095\n",
      "Epoch 2/15\n",
      "786180/786180 [==============================] - 29s - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 3/15\n",
      "786180/786180 [==============================] - 31s - loss: 0.0066 - val_loss: 0.0097\n",
      "Epoch 4/15\n",
      "786180/786180 [==============================] - 35s - loss: 0.0064 - val_loss: 0.0100\n",
      "Epoch 5/15\n",
      "786180/786180 [==============================] - 33s - loss: 0.0063 - val_loss: 0.0106\n",
      "Epoch 6/15\n",
      "786180/786180 [==============================] - 33s - loss: 0.0062 - val_loss: 0.0101\n",
      "Epoch 7/15\n",
      "786180/786180 [==============================] - 32s - loss: 0.0061 - val_loss: 0.0102\n",
      "Epoch 8/15\n",
      "786180/786180 [==============================] - 30s - loss: 0.0060 - val_loss: 0.0103\n",
      "Epoch 9/15\n",
      "786180/786180 [==============================] - 29s - loss: 0.0060 - val_loss: 0.0098\n",
      "Epoch 10/15\n",
      "786180/786180 [==============================] - 30s - loss: 0.0059 - val_loss: 0.0098\n",
      "Epoch 11/15\n",
      "786180/786180 [==============================] - 29s - loss: 0.0059 - val_loss: 0.0102\n",
      "Epoch 12/15\n",
      "786180/786180 [==============================] - 29s - loss: 0.0058 - val_loss: 0.0106\n",
      "Epoch 13/15\n",
      "786180/786180 [==============================] - 29s - loss: 0.0058 - val_loss: 0.0100\n",
      "Epoch 14/15\n",
      "786180/786180 [==============================] - 32s - loss: 0.0058 - val_loss: 0.0098\n",
      "Epoch 15/15\n",
      "786180/786180 [==============================] - 32s - loss: 0.0058 - val_loss: 0.0101\n",
      "train_rmspe :0.136156,\tvalid_rmspe:0.147414\n"
     ]
    }
   ],
   "source": [
    "max_log_y=np.max(np.log(y_train_data))\n",
    "\n",
    "def _val_for_fit(val):\n",
    "    val=np.log(val)\n",
    "    return val/max_log_y\n",
    "def _val_for_pred(val):\n",
    "    return np.exp(val*max_log_y)\n",
    "\n",
    "def calc_predict_rmspe(trained_model,x_data,y_data):\n",
    "    flag=y_data>0\n",
    "    predicted_value=trained_model.predict( x_data).flatten()\n",
    "    return np.sqrt(np.mean(np.power((_val_for_pred(predicted_value[flag])-(y_data[flag]))/y_data[flag],2.0)))\n",
    "    \n",
    "    \n",
    "\n",
    "nb_epoch=15\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=256\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 思路：重写loss函数\n",
    "- 使用其他函数作为loss函数，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_embedding_space(x):\n",
    "    dict_map={\n",
    "        1115:50,\n",
    "        365:30,\n",
    "        31:10,\n",
    "        16:10,\n",
    "        15:10,\n",
    "        12:8,\n",
    "        7:6,\n",
    "        4:3,        \n",
    "        3:2,\n",
    "        2:1,\n",
    "        1:1\n",
    "    }\n",
    "    return dict_map[x]\n",
    "\n",
    "\n",
    "models=[]\n",
    "for ii in feature_x_list:\n",
    "    input_range=dict_feature_range[ii]\n",
    "    \n",
    "#     if input_range ==2 :\n",
    "#         temp_name='Dense_'+ii\n",
    "#         model= Sequential(name=temp_name)\n",
    "#         model.add(Dense(1, input_dim=1))\n",
    "#         models.append(model)\n",
    "#     else:    \n",
    "    embedding_space=calc_embedding_space(input_range)        \n",
    "    temp_name='Embedding_'+ii\n",
    "    model=Sequential(name=temp_name)\n",
    "    model.add(Embedding(input_range,embedding_space,input_length=1))\n",
    "    model.add(Reshape((embedding_space, ), input_shape=(1,embedding_space)))\n",
    "    models.append(model)\n",
    "\n",
    "    \n",
    "max_log_y=np.max(np.log(y_train_data))\n",
    "\n",
    "def _val_for_fit(val):\n",
    "    val=np.log(val)\n",
    "    return val/max_log_y\n",
    "\n",
    "def _val_for_pred(val):\n",
    "    return tf.exp(val*max_log_y)        \n",
    "\n",
    "def loss_func_rmspe(y_true,y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.pow((_val_for_pred(y_pred)-_val_for_pred(y_true))/_val_for_pred(y_true),2.0)))\n",
    "\n",
    "def calc_predict_rmspe(trained_model,x_data,y_data):\n",
    "    predicted_value=trained_model.predict( x_data).flatten()\n",
    "    return np.sqrt(np.mean(np.power((np.exp(predicted_value*max_log_y)-y_data.astype(np.float32))/y_data.astype(np.float32),2.0)))    \n",
    "\n",
    "\n",
    "        \n",
    "def create_embedding_model():\n",
    "    dropout_rate=0.2\n",
    "\n",
    "    embedding_model=Sequential()\n",
    "    embedding_model.add(Merge(models,mode='concat',concat_axis=-1))\n",
    "\n",
    "    embedding_model.add(Dense(512,kernel_initializer='uniform'))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dense(128,kernel_initializer='uniform'))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dense(32,kernel_initializer='uniform'))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dropout(dropout_rate))\n",
    "    embedding_model.add(Dense(1))\n",
    "    embedding_model.add(Activation('sigmoid'))\n",
    "\n",
    "    embedding_model.compile(loss=loss_func_rmspe,optimizer='adam')\n",
    "    return embedding_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/1\n",
      "786180/786180 [==============================] - 31s - loss: 0.2328 - val_loss: 0.1566\n",
      "train_rmspe :0.158865,\tvalid_rmspe:0.158396\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=1\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=256\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/2\n",
      "786180/786180 [==============================] - 31s - loss: 0.2111 - val_loss: 0.1504\n",
      "Epoch 2/2\n",
      "786180/786180 [==============================] - 31s - loss: 0.1295 - val_loss: 0.1526\n",
      "train_rmspe :0.131919,\tvalid_rmspe:0.154768\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=2\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=256\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/3\n",
      "786180/786180 [==============================] - 30s - loss: 0.2110 - val_loss: 0.1518\n",
      "Epoch 2/3\n",
      "786180/786180 [==============================] - 30s - loss: 0.1201 - val_loss: 0.1542\n",
      "Epoch 3/3\n",
      "786180/786180 [==============================] - 31s - loss: 0.1155 - val_loss: 0.1466\n",
      "train_rmspe :0.117898,\tvalid_rmspe:0.148456\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=3\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=256\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/4\n",
      "786180/786180 [==============================] - 30s - loss: 0.2089 - val_loss: 0.1489\n",
      "Epoch 2/4\n",
      "786180/786180 [==============================] - 30s - loss: 0.1268 - val_loss: 0.1477\n",
      "Epoch 3/4\n",
      "786180/786180 [==============================] - 31s - loss: 0.1144 - val_loss: 0.1390\n",
      "Epoch 4/4\n",
      "786180/786180 [==============================] - 31s - loss: 0.1116 - val_loss: 0.1424\n",
      "train_rmspe :0.106875,\tvalid_rmspe:0.144426\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=4\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=256\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/5\n",
      "786180/786180 [==============================] - 30s - loss: 0.2091 - val_loss: 0.1385\n",
      "Epoch 2/5\n",
      "786180/786180 [==============================] - 30s - loss: 0.1172 - val_loss: 0.1415\n",
      "Epoch 3/5\n",
      "786180/786180 [==============================] - 31s - loss: 0.1136 - val_loss: 0.1539\n",
      "Epoch 4/5\n",
      "786180/786180 [==============================] - 31s - loss: 0.1099 - val_loss: 0.1413\n",
      "Epoch 5/5\n",
      "786180/786180 [==============================] - 31s - loss: 0.1064 - val_loss: 0.1356\n",
      "train_rmspe :0.102818,\tvalid_rmspe:0.137644\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=5\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=256\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 思路：重写loss函数\n",
    "- 使用其他函数作为loss函数，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_embedding_space(x):\n",
    "    dict_map={\n",
    "        1115:50,\n",
    "        365:30,\n",
    "        31:10,\n",
    "        16:10,\n",
    "        15:10,\n",
    "        12:8,\n",
    "        7:6,\n",
    "        4:3,        \n",
    "        3:2,\n",
    "        2:1,\n",
    "        1:1\n",
    "    }\n",
    "    return dict_map[x]\n",
    "\n",
    "\n",
    "models=[]\n",
    "for ii in feature_x_list:\n",
    "    input_range=dict_feature_range[ii]\n",
    "    \n",
    "#     if input_range ==2 :\n",
    "#         temp_name='Dense_'+ii\n",
    "#         model= Sequential(name=temp_name)\n",
    "#         model.add(Dense(1, input_dim=1))\n",
    "#         models.append(model)\n",
    "#     else:    \n",
    "    embedding_space=calc_embedding_space(input_range)        \n",
    "    temp_name='Embedding_'+ii\n",
    "    model=Sequential(name=temp_name)\n",
    "    model.add(Embedding(input_range,embedding_space,input_length=1))\n",
    "    model.add(Reshape((embedding_space, ), input_shape=(1,embedding_space)))\n",
    "    models.append(model)\n",
    "\n",
    "    \n",
    "max_log_y=np.max(np.log(y_train_data))\n",
    "\n",
    "def _val_for_fit(val):\n",
    "    val=np.log(val)\n",
    "    return val/max_log_y\n",
    "\n",
    "def _val_for_pred(val):\n",
    "    return tf.exp(val*max_log_y)        \n",
    "\n",
    "def loss_func_rmspe(y_true,y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.pow((_val_for_pred(y_pred)-_val_for_pred(y_true))/_val_for_pred(y_true),2.0)))\n",
    "\n",
    "def calc_predict_rmspe(trained_model,x_data,y_data):\n",
    "    predicted_value=trained_model.predict( x_data).flatten()\n",
    "    return np.sqrt(np.mean(np.power((np.exp(predicted_value*max_log_y)-y_data.astype(np.float32))/y_data.astype(np.float32),2.0)))    \n",
    "        \n",
    "def create_embedding_model():\n",
    "    dropout_rate=0.2\n",
    "\n",
    "    embedding_model=Sequential()\n",
    "    embedding_model.add(Merge(models,mode='concat',concat_axis=-1))\n",
    "\n",
    "    embedding_model.add(Dense(1024,kernel_initializer='uniform'))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dense(256,kernel_initializer='uniform'))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dense(64,kernel_initializer='uniform'))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dropout(dropout_rate))\n",
    "    embedding_model.add(Dense(1))\n",
    "    embedding_model.add(Activation('sigmoid'))\n",
    "\n",
    "    embedding_model.compile(loss=loss_func_rmspe,optimizer='adam')\n",
    "    return embedding_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/1\n",
      "786180/786180 [==============================] - 54s - loss: 0.2104 - val_loss: 0.1472\n",
      "train_rmspe :0.156297,\tvalid_rmspe:0.149000\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=1\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=256\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/2\n",
      "786180/786180 [==============================] - 58s - loss: 0.1933 - val_loss: 0.1390\n",
      "Epoch 2/2\n",
      "786180/786180 [==============================] - 57s - loss: 0.1175 - val_loss: 0.1366\n",
      "train_rmspe :0.130764,\tvalid_rmspe:0.138997\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=2\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=256\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/3\n",
      "786180/786180 [==============================] - 59s - loss: 0.2167 - val_loss: 0.1570\n",
      "Epoch 2/3\n",
      "786180/786180 [==============================] - 60s - loss: 0.1284 - val_loss: 0.1342\n",
      "Epoch 3/3\n",
      "786180/786180 [==============================] - 58s - loss: 0.1094 - val_loss: 0.1299\n",
      "train_rmspe :0.106766,\tvalid_rmspe:0.132173\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=3\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=256\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/4\n",
      "786180/786180 [==============================] - 62s - loss: 0.1854 - val_loss: 0.1361\n",
      "Epoch 2/4\n",
      "786180/786180 [==============================] - 59s - loss: 0.1134 - val_loss: 0.1369\n",
      "Epoch 3/4\n",
      "786180/786180 [==============================] - 58s - loss: 0.1000 - val_loss: 0.1359\n",
      "Epoch 4/4\n",
      "786180/786180 [==============================] - 60s - loss: 0.0973 - val_loss: 0.1530\n",
      "train_rmspe :0.120473,\tvalid_rmspe:0.155199\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=4\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=256\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/5\n",
      "786180/786180 [==============================] - 65s - loss: 0.1848 - val_loss: 0.1450\n",
      "Epoch 2/5\n",
      "786180/786180 [==============================] - 61s - loss: 0.1096 - val_loss: 0.1412\n",
      "Epoch 3/5\n",
      "786180/786180 [==============================] - 59s - loss: 0.1001 - val_loss: 0.1532\n",
      "Epoch 4/5\n",
      "786180/786180 [==============================] - 59s - loss: 0.0965 - val_loss: 0.1427\n",
      "Epoch 5/5\n",
      "786180/786180 [==============================] - 56s - loss: 0.0943 - val_loss: 0.1500\n",
      "train_rmspe :0.112923,\tvalid_rmspe:0.152082\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=5\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=256\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 思路：重写loss函数\n",
    "- 使用其他函数作为loss函数，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_embedding_space(x):\n",
    "    dict_map={\n",
    "        1115:100,\n",
    "        365:80,\n",
    "        31:15,\n",
    "        16:10,\n",
    "        15:10,\n",
    "        12:8,\n",
    "        7:6,\n",
    "        4:3,        \n",
    "        3:2,\n",
    "        2:1,\n",
    "        1:1\n",
    "    }\n",
    "    return dict_map[x]\n",
    "\n",
    "\n",
    "models=[]\n",
    "for ii in feature_x_list:\n",
    "    input_range=dict_feature_range[ii]\n",
    "    \n",
    "#     if input_range ==2 :\n",
    "#         temp_name='Dense_'+ii\n",
    "#         model= Sequential(name=temp_name)\n",
    "#         model.add(Dense(1, input_dim=1))\n",
    "#         models.append(model)\n",
    "#     else:    \n",
    "    embedding_space=calc_embedding_space(input_range)        \n",
    "    temp_name='Embedding_'+ii\n",
    "    model=Sequential(name=temp_name)\n",
    "    model.add(Embedding(input_range,embedding_space,input_length=1))\n",
    "    model.add(Reshape((embedding_space, ), input_shape=(1,embedding_space)))\n",
    "    models.append(model)\n",
    "\n",
    "    \n",
    "max_log_y=np.max(np.log(y_train_data))\n",
    "\n",
    "def _val_for_fit(val):\n",
    "    val=np.log(val)\n",
    "    return val/max_log_y\n",
    "\n",
    "def _val_for_pred(val):\n",
    "    return tf.exp(val*max_log_y)        \n",
    "\n",
    "def loss_func_rmspe(y_true,y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.pow((_val_for_pred(y_pred)-_val_for_pred(y_true))/_val_for_pred(y_true),2.0)))\n",
    "\n",
    "def calc_predict_rmspe(trained_model,x_data,y_data):\n",
    "    predicted_value=trained_model.predict( x_data).flatten()\n",
    "    return np.sqrt(np.mean(np.power((np.exp(predicted_value*max_log_y)-y_data.astype(np.float32))/y_data.astype(np.float32),2.0)))    \n",
    "        \n",
    "def create_embedding_model():\n",
    "    dropout_rate=0.2\n",
    "\n",
    "    embedding_model=Sequential()\n",
    "    embedding_model.add(Merge(models,mode='concat',concat_axis=-1))\n",
    "\n",
    "    embedding_model.add(Dense(1024,kernel_initializer='uniform'))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dense(256,kernel_initializer='uniform'))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dense(64,kernel_initializer='uniform'))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dropout(dropout_rate))\n",
    "    embedding_model.add(Dense(1))\n",
    "    embedding_model.add(Activation('sigmoid'))\n",
    "\n",
    "    embedding_model.compile(loss=loss_func_rmspe,optimizer='adam')\n",
    "    return embedding_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/1\n",
      "786180/786180 [==============================] - 54s - loss: 0.2104 - val_loss: 0.1472\n",
      "train_rmspe :0.156297,\tvalid_rmspe:0.149000\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=1\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=256\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/2\n",
      "786180/786180 [==============================] - 58s - loss: 0.1933 - val_loss: 0.1390\n",
      "Epoch 2/2\n",
      "786180/786180 [==============================] - 57s - loss: 0.1175 - val_loss: 0.1366\n",
      "train_rmspe :0.130764,\tvalid_rmspe:0.138997\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=2\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=256\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/3\n",
      "786180/786180 [==============================] - 59s - loss: 0.2167 - val_loss: 0.1570\n",
      "Epoch 2/3\n",
      "786180/786180 [==============================] - 60s - loss: 0.1284 - val_loss: 0.1342\n",
      "Epoch 3/3\n",
      "786180/786180 [==============================] - 58s - loss: 0.1094 - val_loss: 0.1299\n",
      "train_rmspe :0.106766,\tvalid_rmspe:0.132173\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=3\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=256\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_epoch=4\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=256\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_epoch=5\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=256\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 思路：重写loss函数\n",
    "- 使用其他函数作为loss函数，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_embedding_space(x):\n",
    "    dict_map={\n",
    "        1115:50,\n",
    "        365:30,\n",
    "        31:15,\n",
    "        16:10,\n",
    "        15:10,\n",
    "        12:8,\n",
    "        7:6,\n",
    "        4:3,        \n",
    "        3:2,\n",
    "        2:1,\n",
    "        1:1\n",
    "    }\n",
    "    return dict_map[x]\n",
    "\n",
    "\n",
    "models=[]\n",
    "for ii in feature_x_list:\n",
    "    input_range=dict_feature_range[ii]\n",
    "    \n",
    "#     if input_range ==2 :\n",
    "#         temp_name='Dense_'+ii\n",
    "#         model= Sequential(name=temp_name)\n",
    "#         model.add(Dense(1, input_dim=1))\n",
    "#         models.append(model)\n",
    "#     else:    \n",
    "    embedding_space=calc_embedding_space(input_range)        \n",
    "    temp_name='Embedding_'+ii\n",
    "    model=Sequential(name=temp_name)\n",
    "    model.add(Embedding(input_range,embedding_space,input_length=1))\n",
    "    model.add(Reshape((embedding_space, ), input_shape=(1,embedding_space)))\n",
    "    models.append(model)\n",
    "\n",
    "    \n",
    "max_log_y=np.max(np.log(y_train_data))\n",
    "\n",
    "def _val_for_fit(val):\n",
    "    val=np.log(val)\n",
    "    return val/max_log_y\n",
    "\n",
    "def _val_for_pred(val):\n",
    "    return tf.exp(val*max_log_y)        \n",
    "\n",
    "def loss_func_rmspe(y_true,y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.pow((_val_for_pred(y_pred)-_val_for_pred(y_true))/_val_for_pred(y_true),2.0)))\n",
    "\n",
    "def calc_predict_rmspe(trained_model,x_data,y_data):\n",
    "    predicted_value=trained_model.predict( x_data).flatten()\n",
    "    return np.sqrt(np.mean(np.power((np.exp(predicted_value*max_log_y)-y_data.astype(np.float32))/y_data.astype(np.float32),2.0)))    \n",
    "        \n",
    "def create_embedding_model():\n",
    "    dropout_rate=0.1\n",
    "\n",
    "    embedding_model=Sequential()\n",
    "    embedding_model.add(Merge(models,mode='concat',concat_axis=-1))\n",
    "\n",
    "    embedding_model.add(Dropout(dropout_rate))    \n",
    "    embedding_model.add(Dense(512,\n",
    "                              kernel_initializer='uniform',\n",
    "                              kernel_regularizer=regularizers.l2(0.001),\n",
    "#                               activity_regularizer=regularizers.l1(0.01)\n",
    "                             ))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dense(256,\n",
    "                              kernel_initializer='uniform',\n",
    "                              kernel_regularizer=regularizers.l2(0.001),\n",
    "#                               activity_regularizer=regularizers.l1(0.01)\n",
    "                             ))\n",
    "                             \n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dense(64,\n",
    "                              kernel_initializer='uniform',\n",
    "                            kernel_regularizer=regularizers.l2(0.001),\n",
    "#                               activity_regularizer=regularizers.l1(0.01)\n",
    "                             ))\n",
    "                        \n",
    "    embedding_model.add(Activation('relu'))\n",
    "\n",
    "    embedding_model.add(Dense(1))\n",
    "    embedding_model.add(Activation('sigmoid'))\n",
    "    \n",
    "    \n",
    "    adam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    embedding_model.compile(loss=loss_func_rmspe,optimizer=adam)\n",
    "    return embedding_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/1\n",
      "786180/786180 [==============================] - 49s - loss: 0.1942 - val_loss: 0.1913\n",
      "train_rmspe :0.152905,\tvalid_rmspe:0.180233\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=1\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=256\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/2\n",
      "786180/786180 [==============================] - 49s - loss: 0.1732 - val_loss: 0.1795\n",
      "Epoch 2/2\n",
      "786180/786180 [==============================] - 47s - loss: 0.1443 - val_loss: 0.2005\n",
      "train_rmspe :0.169788,\tvalid_rmspe:0.193751\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=2\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=256\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/3\n",
      "786180/786180 [==============================] - 45s - loss: 0.1635 - val_loss: 0.2001\n",
      "Epoch 2/3\n",
      "786180/786180 [==============================] - 45s - loss: 0.1401 - val_loss: 0.1819\n",
      "Epoch 3/3\n",
      "786180/786180 [==============================] - 45s - loss: 0.1350 - val_loss: 0.1911\n",
      "train_rmspe :0.139354,\tvalid_rmspe:0.183635\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=3\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=256\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 思路：重写loss函数\n",
    "- 使用其他函数作为loss函数，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_embedding_space(x):\n",
    "    dict_map={\n",
    "        1115:50,\n",
    "        365:30,\n",
    "        31:15,\n",
    "        16:10,\n",
    "        15:10,\n",
    "        12:8,\n",
    "        7:6,\n",
    "        4:3,        \n",
    "        3:2,\n",
    "        2:1,\n",
    "        1:1\n",
    "    }\n",
    "    return dict_map[x]\n",
    "\n",
    "\n",
    "models=[]\n",
    "for ii in feature_x_list:\n",
    "    input_range=dict_feature_range[ii]\n",
    "    \n",
    "#     if input_range ==2 :\n",
    "#         temp_name='Dense_'+ii\n",
    "#         model= Sequential(name=temp_name)\n",
    "#         model.add(Dense(1, input_dim=1))\n",
    "#         models.append(model)\n",
    "#     else:    \n",
    "    embedding_space=calc_embedding_space(input_range)        \n",
    "    temp_name='Embedding_'+ii\n",
    "    model=Sequential(name=temp_name)\n",
    "    model.add(Embedding(input_range,embedding_space,input_length=1))\n",
    "    model.add(Reshape((embedding_space, ), input_shape=(1,embedding_space)))\n",
    "    models.append(model)\n",
    "\n",
    "    \n",
    "max_log_y=np.max(np.log(y_train_data))\n",
    "\n",
    "def _val_for_fit(val):\n",
    "    val=np.log(val)\n",
    "    return val/max_log_y\n",
    "\n",
    "def _val_for_pred(val):\n",
    "    return tf.exp(val*max_log_y)        \n",
    "\n",
    "def loss_func_rmspe(y_true,y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.pow((_val_for_pred(y_pred)-_val_for_pred(y_true))/_val_for_pred(y_true),2.0)))\n",
    "\n",
    "def calc_predict_rmspe(trained_model,x_data,y_data):\n",
    "    predicted_value=trained_model.predict( x_data).flatten()\n",
    "    return np.sqrt(np.mean(np.power((np.exp(predicted_value*max_log_y)-y_data.astype(np.float32))/y_data.astype(np.float32),2.0)))    \n",
    "        \n",
    "def create_embedding_model():\n",
    "    dropout_rate=0.0\n",
    "\n",
    "    embedding_model=Sequential()\n",
    "    embedding_model.add(Merge(models,mode='concat',concat_axis=-1))\n",
    "\n",
    "    embedding_model.add(Dropout(dropout_rate))  \n",
    "    \n",
    "    embedding_model.add(Dense(512,\n",
    "                              kernel_initializer='uniform',\n",
    "#                               kernel_regularizer=regularizers.l2(0.001),\n",
    "#                               activity_regularizer=regularizers.l1(0.01)\n",
    "                             ))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dense(256,\n",
    "                              kernel_initializer='uniform',\n",
    "#                               kernel_regularizer=regularizers.l2(0.001),\n",
    "#                               activity_regularizer=regularizers.l1(0.01)\n",
    "                             ))\n",
    "                             \n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dense(64,\n",
    "                              kernel_initializer='uniform',\n",
    "#                               kernel_regularizer=regularizers.l2(0.001),\n",
    "#                               activity_regularizer=regularizers.l1(0.01)\n",
    "                             ))\n",
    "                        \n",
    "    embedding_model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "\n",
    "    embedding_model.add(Dense(1))\n",
    "    embedding_model.add(Activation('sigmoid'))\n",
    "    \n",
    "    \n",
    "    adam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    embedding_model.compile(loss=loss_func_rmspe,optimizer=adam)\n",
    "    return embedding_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/1\n",
      "786180/786180 [==============================] - 27s - loss: 0.2300 - val_loss: 0.1603\n",
      "train_rmspe :0.163457,\tvalid_rmspe:0.161508\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=1\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/2\n",
      "786180/786180 [==============================] - 28s - loss: 0.2255 - val_loss: 0.1531\n",
      "Epoch 2/2\n",
      "786180/786180 [==============================] - 30s - loss: 0.1639 - val_loss: 0.1420\n",
      "train_rmspe :0.156099,\tvalid_rmspe:0.143310\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=2\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/3\n",
      "786180/786180 [==============================] - 38s - loss: 0.1886 - val_loss: 0.1484\n",
      "Epoch 2/3\n",
      "786180/786180 [==============================] - 37s - loss: 0.1255 - val_loss: 0.1418\n",
      "Epoch 3/3\n",
      "786180/786180 [==============================] - 37s - loss: 0.1121 - val_loss: 0.1494\n",
      "train_rmspe :0.125123,\tvalid_rmspe:0.151603\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=3\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=256\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_embedding_space(x):\n",
    "    dict_map={\n",
    "        1115:50,\n",
    "        365:30,\n",
    "        31:15,\n",
    "        16:10,\n",
    "        15:10,\n",
    "        12:8,\n",
    "        7:6,\n",
    "        4:3,        \n",
    "        3:2,\n",
    "        2:1,\n",
    "        1:1\n",
    "    }\n",
    "    return dict_map[x]\n",
    "\n",
    "\n",
    "models=[]\n",
    "for ii in feature_x_list:\n",
    "    input_range=dict_feature_range[ii]\n",
    "    \n",
    "#     if input_range ==2 :\n",
    "#         temp_name='Dense_'+ii\n",
    "#         model= Sequential(name=temp_name)\n",
    "#         model.add(Dense(1, input_dim=1))\n",
    "#         models.append(model)\n",
    "#     else:    \n",
    "    embedding_space=calc_embedding_space(input_range)        \n",
    "    temp_name='Embedding_'+ii\n",
    "    model=Sequential(name=temp_name)\n",
    "    model.add(Embedding(input_range,embedding_space,input_length=1))\n",
    "    model.add(Reshape((embedding_space, ), input_shape=(1,embedding_space)))\n",
    "    models.append(model)\n",
    "\n",
    "    \n",
    "max_log_y=np.max(np.log(y_train_data))\n",
    "\n",
    "def _val_for_fit(val):\n",
    "    val=np.log(val)\n",
    "    return val/max_log_y\n",
    "\n",
    "def _val_for_pred(val):\n",
    "    return tf.exp(val*max_log_y)        \n",
    "\n",
    "def loss_func_rmspe(y_true,y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.pow((_val_for_pred(y_pred)-_val_for_pred(y_true))/_val_for_pred(y_true),2.0)))\n",
    "\n",
    "def calc_predict_rmspe(trained_model,x_data,y_data):\n",
    "    predicted_value=trained_model.predict( x_data).flatten()\n",
    "    return np.sqrt(np.mean(np.power((np.exp(predicted_value*max_log_y)-y_data.astype(np.float32))/y_data.astype(np.float32),2.0)))    \n",
    "        \n",
    "def create_embedding_model():\n",
    "    dropout_rate=0.01\n",
    "\n",
    "    embedding_model=Sequential()\n",
    "    embedding_model.add(Merge(models,mode='concat',concat_axis=-1))\n",
    "\n",
    "    embedding_model.add(Dropout(dropout_rate))  \n",
    "    \n",
    "    embedding_model.add(Dense(512,\n",
    "                              kernel_initializer='uniform',\n",
    "#                               kernel_regularizer=regularizers.l2(0.001),\n",
    "#                               activity_regularizer=regularizers.l1(0.01)\n",
    "                             ))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dense(256,\n",
    "                              kernel_initializer='uniform',\n",
    "#                               kernel_regularizer=regularizers.l2(0.001),\n",
    "#                               activity_regularizer=regularizers.l1(0.01)\n",
    "                             ))\n",
    "                             \n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dense(64,\n",
    "                              kernel_initializer='uniform',\n",
    "#                               kernel_regularizer=regularizers.l2(0.001),\n",
    "#                               activity_regularizer=regularizers.l1(0.01)\n",
    "                             ))\n",
    "                        \n",
    "    embedding_model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "\n",
    "    embedding_model.add(Dense(1))\n",
    "    embedding_model.add(Activation('sigmoid'))\n",
    "    \n",
    "    \n",
    "    adam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    embedding_model.compile(loss=loss_func_rmspe,optimizer=adam)\n",
    "    return embedding_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/1\n",
      "786180/786180 [==============================] - 28s - loss: 0.1676 - val_loss: 0.1597\n",
      "train_rmspe :0.173919,\tvalid_rmspe:0.161094\n",
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/2\n",
      "786180/786180 [==============================] - 29s - loss: 0.1446 - val_loss: 0.1564\n",
      "Epoch 2/2\n",
      "786180/786180 [==============================] - 28s - loss: 0.1180 - val_loss: 0.1576\n",
      "train_rmspe :0.125046,\tvalid_rmspe:0.158702\n",
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/3\n",
      "786180/786180 [==============================] - 29s - loss: 0.1337 - val_loss: 0.1655\n",
      "Epoch 2/3\n",
      "786180/786180 [==============================] - 29s - loss: 0.1111 - val_loss: 0.1605\n",
      "Epoch 3/3\n",
      "786180/786180 [==============================] - 29s - loss: 0.1038 - val_loss: 0.1597\n",
      "train_rmspe :0.108715,\tvalid_rmspe:0.160889\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=1\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)\n",
    "\n",
    "nb_epoch=2\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)\n",
    "\n",
    "nb_epoch=3\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_embedding_space(x):\n",
    "    dict_map={\n",
    "        1115:50,\n",
    "        365:30,\n",
    "        31:15,\n",
    "        16:10,\n",
    "        15:10,\n",
    "        12:8,\n",
    "        7:6,\n",
    "        4:3,        \n",
    "        3:2,\n",
    "        2:1,\n",
    "        1:1\n",
    "    }\n",
    "    return dict_map[x]\n",
    "\n",
    "\n",
    "models=[]\n",
    "for ii in feature_x_list:\n",
    "    input_range=dict_feature_range[ii]\n",
    "    \n",
    "#     if input_range ==2 :\n",
    "#         temp_name='Dense_'+ii\n",
    "#         model= Sequential(name=temp_name)\n",
    "#         model.add(Dense(1, input_dim=1))\n",
    "#         models.append(model)\n",
    "#     else:    \n",
    "    embedding_space=calc_embedding_space(input_range)        \n",
    "    temp_name='Embedding_'+ii\n",
    "    model=Sequential(name=temp_name)\n",
    "    model.add(Embedding(input_range,embedding_space,input_length=1))\n",
    "    model.add(Reshape((embedding_space, ), input_shape=(1,embedding_space)))\n",
    "    models.append(model)\n",
    "\n",
    "    \n",
    "max_log_y=np.max(np.log(y_train_data))\n",
    "\n",
    "def _val_for_fit(val):\n",
    "    val=np.log(val)\n",
    "    return val/max_log_y\n",
    "\n",
    "def _val_for_pred(val):\n",
    "    return tf.exp(val*max_log_y)        \n",
    "\n",
    "def loss_func_rmspe(y_true,y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.pow((_val_for_pred(y_pred)-_val_for_pred(y_true))/_val_for_pred(y_true),2.0)))\n",
    "\n",
    "def calc_predict_rmspe(trained_model,x_data,y_data):\n",
    "    predicted_value=trained_model.predict( x_data).flatten()\n",
    "    return np.sqrt(np.mean(np.power((np.exp(predicted_value*max_log_y)-y_data.astype(np.float32))/y_data.astype(np.float32),2.0)))    \n",
    "        \n",
    "def create_embedding_model():\n",
    "    dropout_rate=0.05\n",
    "\n",
    "    embedding_model=Sequential()\n",
    "    embedding_model.add(Merge(models,mode='concat',concat_axis=-1))\n",
    "\n",
    "    embedding_model.add(Dropout(dropout_rate))  \n",
    "    \n",
    "    embedding_model.add(Dense(512,\n",
    "                              kernel_initializer='uniform',\n",
    "#                               kernel_regularizer=regularizers.l2(0.001),\n",
    "#                               activity_regularizer=regularizers.l1(0.01)\n",
    "                             ))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dense(256,\n",
    "                              kernel_initializer='uniform',\n",
    "#                               kernel_regularizer=regularizers.l2(0.001),\n",
    "#                               activity_regularizer=regularizers.l1(0.01)\n",
    "                             ))\n",
    "                             \n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dense(64,\n",
    "                              kernel_initializer='uniform',\n",
    "#                               kernel_regularizer=regularizers.l2(0.001),\n",
    "#                               activity_regularizer=regularizers.l1(0.01)\n",
    "                             ))\n",
    "                        \n",
    "    embedding_model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "\n",
    "    embedding_model.add(Dense(1))\n",
    "    embedding_model.add(Activation('sigmoid'))\n",
    "    \n",
    "    \n",
    "    adam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    embedding_model.compile(loss=loss_func_rmspe,optimizer=adam)\n",
    "    return embedding_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/1\n",
      "786180/786180 [==============================] - 31s - loss: 0.1772 - val_loss: 0.1608\n",
      "train_rmspe :0.162839,\tvalid_rmspe:0.162016\n",
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/2\n",
      "786180/786180 [==============================] - 30s - loss: 0.1491 - val_loss: 0.1691\n",
      "Epoch 2/2\n",
      "786180/786180 [==============================] - 29s - loss: 0.1256 - val_loss: 0.1570\n",
      "train_rmspe :0.143385,\tvalid_rmspe:0.157924\n",
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/3\n",
      "786180/786180 [==============================] - 30s - loss: 0.1439 - val_loss: 0.1650\n",
      "Epoch 2/3\n",
      "786180/786180 [==============================] - 29s - loss: 0.1218 - val_loss: 0.1546\n",
      "Epoch 3/3\n",
      "786180/786180 [==============================] - 29s - loss: 0.1114 - val_loss: 0.1492\n",
      "train_rmspe :0.122826,\tvalid_rmspe:0.150442\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=1\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)\n",
    "\n",
    "nb_epoch=2\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)\n",
    "\n",
    "nb_epoch=3\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_embedding_space(x):\n",
    "    dict_map={\n",
    "        1115:50,\n",
    "        365:30,\n",
    "        31:15,\n",
    "        16:10,\n",
    "        15:10,\n",
    "        12:8,\n",
    "        7:6,\n",
    "        4:3,        \n",
    "        3:2,\n",
    "        2:1,\n",
    "        1:1\n",
    "    }\n",
    "    return dict_map[x]\n",
    "\n",
    "\n",
    "models=[]\n",
    "for ii in feature_x_list:\n",
    "    input_range=dict_feature_range[ii]\n",
    "    \n",
    "#     if input_range ==2 :\n",
    "#         temp_name='Dense_'+ii\n",
    "#         model= Sequential(name=temp_name)\n",
    "#         model.add(Dense(1, input_dim=1))\n",
    "#         models.append(model)\n",
    "#     else:    \n",
    "    embedding_space=calc_embedding_space(input_range)        \n",
    "    temp_name='Embedding_'+ii\n",
    "    model=Sequential(name=temp_name)\n",
    "    model.add(Embedding(input_range,embedding_space,input_length=1))\n",
    "    model.add(Reshape((embedding_space, ), input_shape=(1,embedding_space)))\n",
    "    models.append(model)\n",
    "\n",
    "    \n",
    "max_log_y=np.max(np.log(y_train_data))\n",
    "\n",
    "def _val_for_fit(val):\n",
    "    val=np.log(val)\n",
    "    return val/max_log_y\n",
    "\n",
    "def _val_for_pred(val):\n",
    "    return tf.exp(val*max_log_y)        \n",
    "\n",
    "def loss_func_rmspe(y_true,y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.pow((_val_for_pred(y_pred)-_val_for_pred(y_true))/_val_for_pred(y_true),2.0)))\n",
    "\n",
    "def calc_predict_rmspe(trained_model,x_data,y_data):\n",
    "    predicted_value=trained_model.predict( x_data).flatten()\n",
    "    return np.sqrt(np.mean(np.power((np.exp(predicted_value*max_log_y)-y_data.astype(np.float32))/y_data.astype(np.float32),2.0)))    \n",
    "        \n",
    "def create_embedding_model():\n",
    "    dropout_rate=0.02\n",
    "\n",
    "    embedding_model=Sequential()\n",
    "    embedding_model.add(Merge(models,mode='concat',concat_axis=-1))\n",
    "\n",
    "    embedding_model.add(Dropout(dropout_rate))  \n",
    "    \n",
    "    embedding_model.add(Dense(512,\n",
    "                              kernel_initializer='uniform',\n",
    "#                               kernel_regularizer=regularizers.l2(0.001),\n",
    "#                               activity_regularizer=regularizers.l1(0.01)\n",
    "                             ))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dense(256,\n",
    "                              kernel_initializer='uniform',\n",
    "#                               kernel_regularizer=regularizers.l2(0.001),\n",
    "#                               activity_regularizer=regularizers.l1(0.01)\n",
    "                             ))\n",
    "                             \n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dense(64,\n",
    "                              kernel_initializer='uniform',\n",
    "#                               kernel_regularizer=regularizers.l2(0.001),\n",
    "#                               activity_regularizer=regularizers.l1(0.01)\n",
    "                             ))\n",
    "                        \n",
    "    embedding_model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "\n",
    "    embedding_model.add(Dense(1))\n",
    "    embedding_model.add(Activation('sigmoid'))\n",
    "    \n",
    "    \n",
    "    adam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    embedding_model.compile(loss=loss_func_rmspe,optimizer=adam)\n",
    "    return embedding_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/1\n",
      "786180/786180 [==============================] - 29s - loss: 0.1708 - val_loss: 0.1548\n",
      "train_rmspe :0.162046,\tvalid_rmspe:0.156194\n",
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/2\n",
      "786180/786180 [==============================] - 29s - loss: 0.1473 - val_loss: 0.1586\n",
      "Epoch 2/2\n",
      "786180/786180 [==============================] - 29s - loss: 0.1197 - val_loss: 0.1556\n",
      "train_rmspe :0.156010,\tvalid_rmspe:0.156525\n",
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/3\n",
      "786180/786180 [==============================] - 32s - loss: 0.1350 - val_loss: 0.1648\n",
      "Epoch 2/3\n",
      "786180/786180 [==============================] - 30s - loss: 0.1149 - val_loss: 0.1565\n",
      "Epoch 3/3\n",
      "786180/786180 [==============================] - 30s - loss: 0.1079 - val_loss: 0.1573\n",
      "train_rmspe :0.118726,\tvalid_rmspe:0.158317\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=1\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)\n",
    "\n",
    "nb_epoch=2\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)\n",
    "\n",
    "nb_epoch=3\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_embedding_space(x):\n",
    "    dict_map={\n",
    "        1115:100,\n",
    "        365:80,\n",
    "        31:15,\n",
    "        16:10,\n",
    "        15:10,\n",
    "        12:8,\n",
    "        7:6,\n",
    "        4:3,        \n",
    "        3:2,\n",
    "        2:1,\n",
    "        1:1\n",
    "    }\n",
    "    return dict_map[x]\n",
    "\n",
    "\n",
    "models=[]\n",
    "for ii in feature_x_list:\n",
    "    input_range=dict_feature_range[ii]\n",
    "    \n",
    "#     if input_range ==2 :\n",
    "#         temp_name='Dense_'+ii\n",
    "#         model= Sequential(name=temp_name)\n",
    "#         model.add(Dense(1, input_dim=1))\n",
    "#         models.append(model)\n",
    "#     else:    \n",
    "    embedding_space=calc_embedding_space(input_range)        \n",
    "    temp_name='Embedding_'+ii\n",
    "    model=Sequential(name=temp_name)\n",
    "    model.add(Embedding(input_range,embedding_space,input_length=1))\n",
    "    model.add(Reshape((embedding_space, ), input_shape=(1,embedding_space)))\n",
    "    models.append(model)\n",
    "\n",
    "    \n",
    "max_log_y=np.max(np.log(y_train_data))\n",
    "\n",
    "def _val_for_fit(val):\n",
    "    val=np.log(val)\n",
    "    return val/max_log_y\n",
    "\n",
    "def _val_for_pred(val):\n",
    "    return tf.exp(val*max_log_y)        \n",
    "\n",
    "def loss_func_rmspe(y_true,y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.pow((_val_for_pred(y_pred)-_val_for_pred(y_true))/_val_for_pred(y_true),2.0)))\n",
    "\n",
    "def calc_predict_rmspe(trained_model,x_data,y_data):\n",
    "    predicted_value=trained_model.predict( x_data).flatten()\n",
    "    return np.sqrt(np.mean(np.power((np.exp(predicted_value*max_log_y)-y_data.astype(np.float32))/y_data.astype(np.float32),2.0)))    \n",
    "        \n",
    "def create_embedding_model():\n",
    "    dropout_rate=0.25\n",
    "\n",
    "    embedding_model=Sequential()\n",
    "    embedding_model.add(Merge(models,mode='concat',concat_axis=-1))\n",
    "\n",
    "    embedding_model.add(Dense(1024,kernel_initializer='uniform'))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dense(256,kernel_initializer='uniform'))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dense(64,kernel_initializer='uniform'))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dropout(dropout_rate))\n",
    "    embedding_model.add(Dense(1))\n",
    "    embedding_model.add(Activation('sigmoid'))\n",
    "\n",
    "    embedding_model.compile(loss=loss_func_rmspe,optimizer='adam')\n",
    "    return embedding_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/1\n",
      "786180/786180 [==============================] - 56s - loss: 0.2533 - val_loss: 0.1524\n",
      "train_rmspe :0.173747,\tvalid_rmspe:0.153495\n",
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/2\n",
      "786180/786180 [==============================] - 73s - loss: 0.2296 - val_loss: 0.1421\n",
      "Epoch 2/2\n",
      "786180/786180 [==============================] - 53s - loss: 0.1583 - val_loss: 0.1337\n",
      "train_rmspe :0.168907,\tvalid_rmspe:0.135155\n",
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/3\n",
      "786180/786180 [==============================] - 51s - loss: 0.2395 - val_loss: 0.1415\n",
      "Epoch 2/3\n",
      "786180/786180 [==============================] - 50s - loss: 0.1587 - val_loss: 0.1330\n",
      "Epoch 3/3\n",
      "786180/786180 [==============================] - 51s - loss: 0.1188 - val_loss: 0.1408\n",
      "train_rmspe :0.114575,\tvalid_rmspe:0.142446\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=1\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)\n",
    "\n",
    "nb_epoch=2\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)\n",
    "\n",
    "nb_epoch=3\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_embedding_space(x):\n",
    "    dict_map={\n",
    "        1115:100,\n",
    "        365:80,\n",
    "        31:15,\n",
    "        16:10,\n",
    "        15:10,\n",
    "        12:8,\n",
    "        7:6,\n",
    "        4:3,        \n",
    "        3:2,\n",
    "        2:1,\n",
    "        1:1\n",
    "    }\n",
    "    return dict_map[x]\n",
    "\n",
    "\n",
    "models=[]\n",
    "for ii in feature_x_list:\n",
    "    input_range=dict_feature_range[ii]\n",
    "    \n",
    "#     if input_range ==2 :\n",
    "#         temp_name='Dense_'+ii\n",
    "#         model= Sequential(name=temp_name)\n",
    "#         model.add(Dense(1, input_dim=1))\n",
    "#         models.append(model)\n",
    "#     else:    \n",
    "    embedding_space=calc_embedding_space(input_range)        \n",
    "    temp_name='Embedding_'+ii\n",
    "    model=Sequential(name=temp_name)\n",
    "    model.add(Embedding(input_range,embedding_space,input_length=1))\n",
    "    model.add(Reshape((embedding_space, ), input_shape=(1,embedding_space)))\n",
    "    models.append(model)\n",
    "\n",
    "    \n",
    "max_log_y=np.max(np.log(y_train_data))\n",
    "\n",
    "def _val_for_fit(val):\n",
    "    val=np.log(val)\n",
    "    return val/max_log_y\n",
    "\n",
    "def _val_for_pred(val):\n",
    "    return tf.exp(val*max_log_y)        \n",
    "\n",
    "def loss_func_rmspe(y_true,y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.pow((_val_for_pred(y_pred)-_val_for_pred(y_true))/_val_for_pred(y_true),2.0)))\n",
    "\n",
    "def calc_predict_rmspe(trained_model,x_data,y_data):\n",
    "    predicted_value=trained_model.predict( x_data).flatten()\n",
    "    return np.sqrt(np.mean(np.power((np.exp(predicted_value*max_log_y)-y_data.astype(np.float32))/y_data.astype(np.float32),2.0)))    \n",
    "        \n",
    "def create_embedding_model():\n",
    "    dropout_rate=0.3\n",
    "\n",
    "    embedding_model=Sequential()\n",
    "    embedding_model.add(Merge(models,mode='concat',concat_axis=-1))\n",
    "\n",
    "    embedding_model.add(Dense(1024,kernel_initializer='uniform'))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dense(256,kernel_initializer='uniform'))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dense(64,kernel_initializer='uniform'))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dropout(dropout_rate))\n",
    "    embedding_model.add(Dense(1))\n",
    "    embedding_model.add(Activation('sigmoid'))\n",
    "\n",
    "    embedding_model.compile(loss=loss_func_rmspe,optimizer='adam')\n",
    "    return embedding_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/1\n",
      "786180/786180 [==============================] - 57s - loss: 0.2742 - val_loss: 0.1530\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-51a5b74df967>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                 )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mvalid_rmspe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalc_predict_rmspe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_valid_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtrain_rmspe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalc_predict_rmspe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"train_rmspe :{:f},\\tvalid_rmspe:{:f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_rmspe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_rmspe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-fb8e0cf7bf4b>\u001b[0m in \u001b[0;36mcalc_predict_rmspe\u001b[0;34m(trained_model, x_data, y_data)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalc_predict_rmspe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mpredicted_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_value\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmax_log_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pengjuzhao/anaconda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pengjuzhao/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1570\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1572\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1574\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/Users/pengjuzhao/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1200\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1203\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pengjuzhao/anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2073\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2075\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2076\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pengjuzhao/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pengjuzhao/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pengjuzhao/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/pengjuzhao/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pengjuzhao/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_epoch=1\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/1\n",
      "786180/786180 [==============================] - 52s - loss: 0.2451 - val_loss: 0.1375\n",
      "train_rmspe :0.136074,\tvalid_rmspe:0.138959\n",
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/2\n",
      "786180/786180 [==============================] - 52s - loss: 0.2245 - val_loss: 0.5963\n",
      "Epoch 2/2\n",
      "786180/786180 [==============================] - 51s - loss: 0.1557 - val_loss: 0.1344\n",
      "train_rmspe :0.148553,\tvalid_rmspe:0.135777\n",
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/3\n",
      "786180/786180 [==============================] - 52s - loss: 0.2474 - val_loss: 0.1382\n",
      "Epoch 2/3\n",
      "786180/786180 [==============================] - 50s - loss: 0.1642 - val_loss: 0.1357\n",
      "Epoch 3/3\n",
      "786180/786180 [==============================] - 51s - loss: 0.1169 - val_loss: 0.1307\n",
      "train_rmspe :0.146995,\tvalid_rmspe:0.132269\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=1\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)\n",
    "\n",
    "nb_epoch=2\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)\n",
    "\n",
    "nb_epoch=3\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/4\n",
      "786180/786180 [==============================] - 53s - loss: 0.2177 - val_loss: 0.1355\n",
      "Epoch 2/4\n",
      "786180/786180 [==============================] - 54s - loss: 0.1539 - val_loss: 0.1386\n",
      "Epoch 3/4\n",
      "786180/786180 [==============================] - 54s - loss: 0.1139 - val_loss: 0.1292\n",
      "Epoch 4/4\n",
      "786180/786180 [==============================] - 54s - loss: 0.1041 - val_loss: 0.1324\n",
      "train_rmspe :0.140546,\tvalid_rmspe:0.133977\n",
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/5\n",
      "786180/786180 [==============================] - 57s - loss: 0.2285 - val_loss: 0.3411\n",
      "Epoch 2/5\n",
      "786180/786180 [==============================] - 55s - loss: 0.1433 - val_loss: 0.1335\n",
      "Epoch 3/5\n",
      "786180/786180 [==============================] - 55s - loss: 0.1078 - val_loss: 0.1279\n",
      "Epoch 4/5\n",
      "786180/786180 [==============================] - 56s - loss: 0.1018 - val_loss: 0.1301\n",
      "Epoch 5/5\n",
      "786180/786180 [==============================] - 56s - loss: 0.0998 - val_loss: 0.1338\n",
      "train_rmspe :0.128709,\tvalid_rmspe:0.135243\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=4\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)\n",
    "nb_epoch=5\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_embedding_space(x):\n",
    "    dict_map={\n",
    "        1115:100,\n",
    "        365:80,\n",
    "        31:15,\n",
    "        16:10,\n",
    "        15:10,\n",
    "        12:8,\n",
    "        7:6,\n",
    "        4:3,        \n",
    "        3:2,\n",
    "        2:1,\n",
    "        1:1\n",
    "    }\n",
    "    return dict_map[x]\n",
    "\n",
    "\n",
    "models=[]\n",
    "for ii in feature_x_list:\n",
    "    input_range=dict_feature_range[ii]\n",
    "    \n",
    "#     if input_range ==2 :\n",
    "#         temp_name='Dense_'+ii\n",
    "#         model= Sequential(name=temp_name)\n",
    "#         model.add(Dense(1, input_dim=1))\n",
    "#         models.append(model)\n",
    "#     else:    \n",
    "    embedding_space=calc_embedding_space(input_range)        \n",
    "    temp_name='Embedding_'+ii\n",
    "    model=Sequential(name=temp_name)\n",
    "    model.add(Embedding(input_range,embedding_space,input_length=1))\n",
    "    model.add(Reshape((embedding_space, ), input_shape=(1,embedding_space)))\n",
    "    models.append(model)\n",
    "\n",
    "    \n",
    "max_log_y=np.max(np.log(y_train_data))\n",
    "\n",
    "def _val_for_fit(val):\n",
    "    val=np.log(val)\n",
    "    return val/max_log_y\n",
    "\n",
    "def _val_for_pred(val):\n",
    "    return tf.exp(val*max_log_y)        \n",
    "\n",
    "def loss_func_rmspe(y_true,y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.pow((_val_for_pred(y_pred)-_val_for_pred(y_true))/_val_for_pred(y_true),2.0)))\n",
    "\n",
    "def calc_predict_rmspe(trained_model,x_data,y_data):\n",
    "    predicted_value=trained_model.predict( x_data).flatten()\n",
    "    return np.sqrt(np.mean(np.power((np.exp(predicted_value*max_log_y)-y_data.astype(np.float32))/y_data.astype(np.float32),2.0)))    \n",
    "        \n",
    "def create_embedding_model():\n",
    "    dropout_rate=0.35\n",
    "\n",
    "    embedding_model=Sequential()\n",
    "    embedding_model.add(Merge(models,mode='concat',concat_axis=-1))\n",
    "\n",
    "    embedding_model.add(Dense(1024,kernel_initializer='uniform'))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dense(256,kernel_initializer='uniform'))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dense(64,kernel_initializer='uniform'))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dropout(dropout_rate))\n",
    "    embedding_model.add(Dense(1))\n",
    "    embedding_model.add(Activation('sigmoid'))\n",
    "\n",
    "    embedding_model.compile(loss=loss_func_rmspe,optimizer='adam')\n",
    "    return embedding_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/1\n",
      "786180/786180 [==============================] - 55s - loss: 0.2831 - val_loss: 0.1549\n",
      "train_rmspe :0.182888,\tvalid_rmspe:0.156200\n",
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/2\n",
      "786180/786180 [==============================] - 58s - loss: 0.2757 - val_loss: 0.1532\n",
      "Epoch 2/2\n",
      "786180/786180 [==============================] - 54s - loss: 0.1635 - val_loss: 0.1403\n",
      "train_rmspe :0.140503,\tvalid_rmspe:0.141535\n",
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/3\n",
      "786180/786180 [==============================] - 57s - loss: 0.2640 - val_loss: 0.1440\n",
      "Epoch 2/3\n",
      "786180/786180 [==============================] - 56s - loss: 0.1489 - val_loss: 0.1389\n",
      "Epoch 3/3\n",
      "786180/786180 [==============================] - 55s - loss: 0.1204 - val_loss: 0.1338\n",
      "train_rmspe :0.131888,\tvalid_rmspe:0.135204\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=1\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)\n",
    "\n",
    "nb_epoch=2\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)\n",
    "\n",
    "nb_epoch=3\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/4\n",
      "786180/786180 [==============================] - 57s - loss: 0.2485 - val_loss: 0.1406\n",
      "Epoch 2/4\n",
      "786180/786180 [==============================] - 57s - loss: 0.1434 - val_loss: 0.1351\n",
      "Epoch 3/4\n",
      "786180/786180 [==============================] - 54s - loss: 0.1160 - val_loss: 0.1321\n",
      "Epoch 4/4\n",
      "786180/786180 [==============================] - 52s - loss: 0.1122 - val_loss: 0.1395\n",
      "train_rmspe :0.096448,\tvalid_rmspe:0.141115\n",
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/5\n",
      "786180/786180 [==============================] - 58s - loss: 0.2471 - val_loss: 0.1398\n",
      "Epoch 2/5\n",
      "786180/786180 [==============================] - 55s - loss: 0.1508 - val_loss: 0.1319\n",
      "Epoch 3/5\n",
      "786180/786180 [==============================] - 55s - loss: 0.1181 - val_loss: 0.1405\n",
      "Epoch 4/5\n",
      "786180/786180 [==============================] - 55s - loss: 0.1145 - val_loss: 0.1309\n",
      "Epoch 5/5\n",
      "173568/786180 [=====>........................] - ETA: 42s - loss: 0.1078"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-52d180070639>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_val_for_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                            \u001b[0;31m# callbacks=[self.checkpointer],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 )\n",
      "\u001b[0;32m/Users/pengjuzhao/anaconda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Users/pengjuzhao/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pengjuzhao/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1144\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# last batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pengjuzhao/anaconda/lib/python2.7/site-packages/keras/callbacks.pyc\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mt_before_callbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pengjuzhao/anaconda/lib/python2.7/site-packages/keras/callbacks.pyc\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;31m# will be handled by on_epoch_end.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pengjuzhao/anaconda/lib/python2.7/site-packages/keras/utils/generic_utils.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, force)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mprev_total_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\b'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mprev_total_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pengjuzhao/anaconda/lib/python2.7/site-packages/ipykernel/iostream.pyc\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                 \u001b[0;31m# newlines imply flush in subprocesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file"
     ]
    }
   ],
   "source": [
    "nb_epoch=4\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)\n",
    "\n",
    "nb_epoch=5\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_embedding_space(x):\n",
    "    dict_map={\n",
    "        1115:100,\n",
    "        365:80,\n",
    "        31:15,\n",
    "        16:10,\n",
    "        15:10,\n",
    "        12:8,\n",
    "        7:6,\n",
    "        4:3,        \n",
    "        3:2,\n",
    "        2:1,\n",
    "        1:1\n",
    "    }\n",
    "    return dict_map[x]\n",
    "\n",
    "\n",
    "models=[]\n",
    "for ii in feature_x_list:\n",
    "    input_range=dict_feature_range[ii]\n",
    "    \n",
    "#     if input_range ==2 :\n",
    "#         temp_name='Dense_'+ii\n",
    "#         model= Sequential(name=temp_name)\n",
    "#         model.add(Dense(1, input_dim=1))\n",
    "#         models.append(model)\n",
    "#     else:    \n",
    "    embedding_space=calc_embedding_space(input_range)        \n",
    "    temp_name='Embedding_'+ii\n",
    "    model=Sequential(name=temp_name)\n",
    "    model.add(Embedding(input_range,embedding_space,input_length=1))\n",
    "    model.add(Reshape((embedding_space, ), input_shape=(1,embedding_space)))\n",
    "    models.append(model)\n",
    "\n",
    "    \n",
    "max_log_y=np.max(np.log(y_train_data))\n",
    "\n",
    "def _val_for_fit(val):\n",
    "    val=np.log(val)\n",
    "    return val/max_log_y\n",
    "\n",
    "def _val_for_pred(val):\n",
    "    return tf.exp(val*max_log_y)        \n",
    "\n",
    "def loss_func_rmspe(y_true,y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.pow((_val_for_pred(y_pred)-_val_for_pred(y_true))/_val_for_pred(y_true),2.0)))\n",
    "\n",
    "def calc_predict_rmspe(trained_model,x_data,y_data):\n",
    "    predicted_value=trained_model.predict( x_data).flatten()\n",
    "    return np.sqrt(np.mean(np.power((np.exp(predicted_value*max_log_y)-y_data.astype(np.float32))/y_data.astype(np.float32),2.0)))    \n",
    "        \n",
    "def create_embedding_model():\n",
    "    dropout_rate=0.3\n",
    "\n",
    "    embedding_model=Sequential()\n",
    "    embedding_model.add(Merge(models,mode='concat',concat_axis=-1))\n",
    "    \n",
    "    uniform=keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=seed_1)\n",
    "\n",
    "    embedding_model.add(Dense(50,kernel_initializer=uniform))\n",
    "    embedding_model.add(Activation('relu'))\n",
    "#     embedding_model.add(Dense(256,kernel_initializer='uniform'))\n",
    "#     embedding_model.add(Activation('relu'))\n",
    "#     embedding_model.add(Dense(64,kernel_initializer='uniform'))\n",
    "#     embedding_model.add(Activation('relu'))\n",
    "    embedding_model.add(Dropout(dropout_rate,seed=seed_1))\n",
    "    embedding_model.add(Dense(1))\n",
    "    embedding_model.add(Activation('sigmoid'))\n",
    "\n",
    "    embedding_model.compile(loss=loss_func_rmspe,optimizer='adam')\n",
    "    return embedding_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/1\n",
      "786180/786180 [==============================] - 17s - loss: 0.2957 - val_loss: 0.1850\n",
      "train_rmspe :0.195616,\tvalid_rmspe:0.186374\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=1\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 786180 samples, validate on 45852 samples\n",
      "Epoch 1/1\n",
      "786180/786180 [==============================] - 16s - loss: 0.2848 - val_loss: 0.1823\n",
      "train_rmspe :0.186483,\tvalid_rmspe:0.183717\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=1\n",
    "\n",
    "embedding_model=create_embedding_model()\n",
    "embedding_model.fit(x_train_data, _val_for_fit(y_train_data), \n",
    "                    validation_data=(x_valid_data,_val_for_fit(y_valid_data)),\n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=512\n",
    "                           # callbacks=[self.checkpointer],\n",
    "                )\n",
    "valid_rmspe=calc_predict_rmspe(embedding_model,x_valid_data,y_valid_data)\n",
    "train_rmspe=calc_predict_rmspe(embedding_model,x_train_data,y_train_data)\n",
    "print \"train_rmspe :{:f},\\tvalid_rmspe:{:f}\".format(train_rmspe,valid_rmspe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
